{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kd_teacher_student_peer_v2.ipynb","provenance":[{"file_id":"1Yjkh8BnLwDl_0ziqSWc7Q0wLnLUZWqRi","timestamp":1637701390855},{"file_id":"1XVvicESrmi2FwNTNCCjiTJC-JdqUCvL4","timestamp":1635606056154},{"file_id":"1ghEY2lIYJsUC-K63E8VvCjxk0IoKfpz3","timestamp":1635598814073},{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/vision/ipynb/knowledge_distillation.ipynb","timestamp":1635161502502}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"WrVvG0gsHSGe","executionInfo":{"status":"ok","timestamp":1637767984332,"user_tz":300,"elapsed":19182,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"6b14ce69-658c-48cd-dd69-de90bd8e6771"},"source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n","FOLDERNAME = '/MyDrive/Project/'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/{}'.format(FOLDERNAME))\n","\n","%cd '/content/drive/MyDrive/Project/'\n","%pwd"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1XSIbHWFizvrGifGPTwtsmagK2AS8ZE7n/Project\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/.shortcut-targets-by-id/1XSIbHWFizvrGifGPTwtsmagK2AS8ZE7n/Project'"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"pdHhiwRrMKY6"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LnoCIQFXTK3i"},"source":["np.random.seed(682)\n","tf.random.set_seed(682)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNRY26QEMKY8"},"source":["class Distiller(keras.Model):\n","\n","    def __init__(self, student1, student2, student3, teacher):\n","        super(Distiller, self).__init__()\n","        self.teacher = teacher\n","        self.student1 = student1\n","        self.student2 = student2\n","        self.student3 = student3\n","\n","    def compile(\n","        self,\n","        optimizer,\n","        metrics,\n","        student_loss_fn,\n","        distillation_loss_fn,\n","        alpha=0.1,\n","        temperature=3,\n","    ):\n","        \"\"\" Configure the distiller.\n","\n","        Args:\n","            optimizer: Keras optimizer for the student weights\n","            metrics: Keras metrics for evaluation\n","            student_loss_fn: Loss function of difference between student\n","                predictions and ground-truth\n","            distillation_loss_fn: Loss function of difference between soft\n","                student predictions and soft teacher predictions\n","            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n","            temperature: Temperature for softening probability distributions.\n","                Larger temperature gives softer distributions.\n","        \"\"\"\n","        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n","        self.student_loss_fn = student_loss_fn\n","        self.distillation_loss_fn = distillation_loss_fn\n","        self.alpha = alpha\n","        self.temperature = temperature\n","\n","    def train_step(self, data):\n","        \n","        # Unpack data\n","        x, y = data\n","\n","        # Forward pass of teacher\n","        teacher_predictions = self.teacher(x, training=False)\n","\n","        with tf.GradientTape() as tape_student_1:\n","            \n","            # Forward pass of student\n","            student_predictions_1 = self.student1(x, training=True)\n","            student_predictions_2 = self.student2(x, training=False)\n","            student_predictions_3 = self.student3(x, training=False)\n","\n","            # Compute losses\n","            student_loss_1 = self.student_loss_fn(y, student_predictions_1)\n","            student_loss_2 = self.student_loss_fn(y, student_predictions_2)\n","            student_loss_3 = self.student_loss_fn(y, student_predictions_3)\n","\n","            # for student 1\n","            distillation_loss_t_s1 = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_1 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s1_s2 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_1 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_2 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s1_s3 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_1 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_3 / self.temperature, axis=1)\n","            )\n","\n","            loss_1 = 0.1 * student_loss_1 + 0.8 * distillation_loss_t_s1 + 0.1 * (distillation_loss_s1_s2 + distillation_loss_s1_s3)\n","\n","        # Compute gradients\n","        trainable_vars_1 = self.student1.trainable_variables\n","        gradients_1 = tape_student_1.gradient(loss_1, trainable_vars_1)\n","        self.optimizer.apply_gradients(zip(gradients_1, trainable_vars_1))\n","        self.compiled_metrics._metrics[0].update_state(y, student_predictions_1)\n","        \n","\n","        with tf.GradientTape() as tape_student_2:\n","            \n","            # Forward pass of student\n","            student_predictions_1 = self.student1(x, training=False)\n","            student_predictions_2 = self.student2(x, training=True)\n","            student_predictions_3 = self.student3(x, training=False)\n","\n","            # Compute losses\n","            student_loss_1 = self.student_loss_fn(y, student_predictions_1)\n","            student_loss_2 = self.student_loss_fn(y, student_predictions_2)\n","            student_loss_3 = self.student_loss_fn(y, student_predictions_3)\n","            \n","            # for student 2\n","            distillation_loss_t_s2 = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_2 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s2_s1 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_2 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_1 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s2_s3 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_2 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_3 / self.temperature, axis=1)\n","            )\n","\n","            loss_2 = 0.1 * student_loss_2 + 0.8 * distillation_loss_t_s2 + 0.1 * (distillation_loss_s2_s1 + distillation_loss_s2_s3)\n","\n","        trainable_vars_2 = self.student2.trainable_variables\n","        gradients_2 = tape_student_2.gradient(loss_2, trainable_vars_2)\n","\n","        self.optimizer.apply_gradients(zip(gradients_2, trainable_vars_2))\n","\n","        self.compiled_metrics._metrics[1].update_state(y, student_predictions_2)\n","            \n","\n","        with tf.GradientTape() as tape_student_3:\n","            \n","            # Forward pass of student\n","            student_predictions_1 = self.student1(x, training=False)\n","            student_predictions_2 = self.student2(x, training=False)\n","            student_predictions_3 = self.student3(x, training=True)\n","\n","            # Compute losses\n","            student_loss_1 = self.student_loss_fn(y, student_predictions_1)\n","            student_loss_2 = self.student_loss_fn(y, student_predictions_2)\n","            student_loss_3 = self.student_loss_fn(y, student_predictions_3)\n","\n","            # for student 3\n","            distillation_loss_t_s3 = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_3 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s3_s1 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_3 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_1 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s3_s2 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_3 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_2 / self.temperature, axis=1)\n","            )\n","\n","            loss_3 = 0.1 * student_loss_3 + 0.8 * distillation_loss_t_s3 + 0.1 * (distillation_loss_s3_s1 + distillation_loss_s3_s2)\n","\n","        trainable_vars_3 = self.student3.trainable_variables\n","        gradients_3 = tape_student_3.gradient(loss_3, trainable_vars_3)\n","\n","        # Update weights\n","        self.optimizer.apply_gradients(zip(gradients_3, trainable_vars_3))\n","\n","        # Update the metrics configured in `compile()`.     \n","        self.compiled_metrics._metrics[2].update_state(y, student_predictions_3)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.compiled_metrics._metrics}\n","\n","        results.update (\n","            {\"student_loss_1\": student_loss_1,\n","             \"student_loss_2\": student_loss_2,\n","             \"student_loss_3\": student_loss_3,\n","             \"distillation_loss_t_s1\": distillation_loss_t_s1,\n","             \"distillation_loss_s1_s2\": distillation_loss_s1_s2,\n","             \"distillation_loss_s1_s3\": distillation_loss_s1_s3,\n","             \"distillation_loss_t_s2\": distillation_loss_t_s2,\n","             \"distillation_loss_s2_s1\": distillation_loss_s2_s1,\n","             \"distillation_loss_s2_s3\": distillation_loss_s2_s3,\n","             \"distillation_loss_t_s3\": distillation_loss_t_s3,\n","             \"distillation_loss_s3_s1\": distillation_loss_s3_s1,\n","             \"distillation_loss_s3_s2\": distillation_loss_s3_s2}\n","        )\n","\n","        return results\n","\n","\n","    def test_step(self, data):\n","        # Unpack the data\n","        x, y = data\n","\n","        # Compute predictions\n","        y_prediction_1 = self.student1(x, training=False)\n","        y_prediction_2 = self.student2(x, training=False)\n","        y_prediction_3 = self.student3(x, training=False)\n","\n","        # Calculate the loss\n","        student_loss_1 = self.student_loss_fn(y, y_prediction_1)\n","        student_loss_2 = self.student_loss_fn(y, y_prediction_2)\n","        student_loss_3 = self.student_loss_fn(y, y_prediction_3)\n","\n","        # Update the metrics.\n","        self.compiled_metrics._metrics[0].update_state(y, y_prediction_1)\n","        self.compiled_metrics._metrics[1].update_state(y, y_prediction_2)\n","        self.compiled_metrics._metrics[2].update_state(y, y_prediction_3)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.compiled_metrics._metrics}\n","\n","        results.update({\"student_loss_1\": student_loss_1,\n","             \"student_loss_2\": student_loss_2,\n","             \"student_loss_3\": student_loss_3})\n","\n","        return results\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sdQr6q3igRX5"},"source":["teacher = tf.keras.models.load_model('/saved_models/resnet50cifar')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-uiYUJnggJp"},"source":["# Student 3\n","\n","def get_student3():\n","\n","  def preprocess_image_input(input_images):\n","    input_images = tf.cast(input_images, 'float32')\n","    output_ims = tf.keras.applications.mobilenet.preprocess_input(input_images)\n","    return output_ims\n","\n","  class Preprocess(tf.keras.layers.Layer):\n","      def __init__(self):\n","          super(Preprocess, self).__init__()\n","\n","      def call(self, inputs):\n","          return preprocess_image_input(inputs)\n","\n","  student_mobile = tf.keras.applications.MobileNet(\n","      input_shape=(224, 224, 3),\n","      alpha=1.0,\n","      depth_multiplier=1,\n","      dropout=0.001,\n","      include_top=True,\n","      weights=None,\n","      input_tensor=None,\n","      pooling=None,\n","      classes=10,\n","      classifier_activation=None\n","  )\n","\n","  inputs = tf.keras.layers.Input(shape=(32,32,3))\n","  resize = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n","  pre_process = Preprocess()(resize)\n","  resnet_extractor = student_mobile(pre_process)\n","  student = tf.keras.Model(inputs=inputs, outputs = resnet_extractor)\n","  return student\n","\n","student3 = get_student3()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w5vDZ9Cfgmmk"},"source":["# Student 2\n","\n","def get_student2():\n","\n","  # Import necessary components to build LeNet\n","  from keras.models import Sequential\n","  from keras.layers.core import Dense, Activation, Flatten\n","  from keras.layers.convolutional import Conv2D, MaxPooling2D\n","  from keras.regularizers import l2\n","\n","  def lenet_model(img_shape=(32, 32, 3), n_classes=10, l2_reg=0.,\n","    weights=None):\n","\n","    # Initialize model\n","    lenet = Sequential()\n","\n","    # 2 sets of CRP (Convolution, RELU, Pooling)\n","    lenet.add(Conv2D(20, (5, 5), padding=\"same\",\n","      input_shape=img_shape, kernel_regularizer=l2(l2_reg)))\n","    lenet.add(Activation(\"relu\"))\n","    lenet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","    lenet.add(Conv2D(50, (5, 5), padding=\"same\",\n","      kernel_regularizer=l2(l2_reg)))\n","    lenet.add(Activation(\"relu\"))\n","    lenet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","    # Fully connected layers (w/ RELU)\n","    lenet.add(Flatten())\n","    lenet.add(Dense(500, kernel_regularizer=l2(l2_reg)))\n","    lenet.add(Activation(\"relu\"))\n","\n","    # Softmax (for classification)\n","    lenet.add(Dense(n_classes, kernel_regularizer=l2(l2_reg)))\n","    # lenet.add(Activation(\"softmax\"))\n","\n","    if weights is not None:\n","      lenet.load_weights(weights)\n","\n","    # Return the constructed network\n","    return lenet\n","\n","  # Create the student\n","  student = lenet_model()\n","  return student\n","\n","student2 = get_student2()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNKaodNwgvkW"},"source":["# Student 1\n","\n","def get_student1():\n","\n","  from keras.models import Sequential\n","  from keras.layers.core import Dense, Dropout, Activation, Flatten\n","  from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n","  from keras.layers import BatchNormalization\n","  from keras.regularizers import l2\n","\n","  def alexnet_model(img_shape=(32, 32, 3), n_classes=10, l2_reg=0., weights=None):\n","\n","    # Initialize model\n","    alexnet = Sequential()\n","\n","    # Layer 1\n","    alexnet.add(Conv2D(96, (11, 11), input_shape=img_shape,\n","      padding='same', kernel_regularizer=l2(l2_reg)))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # Layer 2\n","    alexnet.add(Conv2D(256, (5, 5), padding='same'))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # Layer 3\n","    alexnet.add(ZeroPadding2D((1, 1)))\n","    alexnet.add(Conv2D(512, (3, 3), padding='same'))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # Layer 4\n","    alexnet.add(ZeroPadding2D((1, 1)))\n","    alexnet.add(Conv2D(1024, (3, 3), padding='same'))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","\n","    # Layer 5\n","    alexnet.add(ZeroPadding2D((1, 1)))\n","    alexnet.add(Conv2D(1024, (3, 3), padding='same'))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # Layer 6\n","    alexnet.add(Flatten())\n","    alexnet.add(Dense(3072))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(Dropout(0.5))\n","\n","    # Layer 7\n","    alexnet.add(Dense(4096))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(Dropout(0.5))\n","\n","    # Layer 8\n","    alexnet.add(Dense(n_classes))\n","\n","    if weights is not None:\n","      alexnet.load_weights(weights)\n","\n","    return alexnet\n","\n","  # Create the student\n","  student = alexnet_model()\n","  return student\n","\n","student1 = get_student1()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nml9yy4rMKZA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637768014014,"user_tz":300,"elapsed":6827,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"4a5e6212-cd9a-4f71-ef52-37a24a9d1801"},"source":["# Prepare the train and test dataset.\n","batch_size = 64\n","\n","(x_train, y_train) , (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n","170508288/170498071 [==============================] - 4s 0us/step\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpmEsuVeXKwC","executionInfo":{"status":"ok","timestamp":1637770347492,"user_tz":300,"elapsed":1295864,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"823b1e11-a87b-4252-cfe7-8c61b15b90f3"},"source":["# Initialize and compile distiller\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1563/1563 [==============================] - 465s 286ms/step - s1_acc: 0.2853 - s2_acc: 0.2443 - s3_acc: 0.4141 - student_loss_1: 129.2667 - student_loss_2: 2.3458 - student_loss_3: 1.3456 - distillation_loss_t_s1: 0.0231 - distillation_loss_s1_s2: 0.0493 - distillation_loss_s1_s3: 0.0319 - distillation_loss_t_s2: 0.0366 - distillation_loss_s2_s1: 0.8824 - distillation_loss_s2_s3: 0.0264 - distillation_loss_t_s3: 0.0097 - distillation_loss_s3_s1: 0.8801 - distillation_loss_s3_s2: 0.0361\n","Epoch 2/5\n","1563/1563 [==============================] - 446s 285ms/step - s1_acc: 0.4004 - s2_acc: 0.3807 - s3_acc: 0.5807 - student_loss_1: 2.3099 - student_loss_2: 1.3470 - student_loss_3: 0.8633 - distillation_loss_t_s1: 0.0216 - distillation_loss_s1_s2: 0.0163 - distillation_loss_s1_s3: 0.0210 - distillation_loss_t_s2: 0.0090 - distillation_loss_s2_s1: 0.0680 - distillation_loss_s2_s3: 0.0125 - distillation_loss_t_s3: 0.0120 - distillation_loss_s3_s1: 0.0697 - distillation_loss_s3_s2: 0.0087\n","Epoch 3/5\n","1563/1563 [==============================] - 447s 286ms/step - s1_acc: 0.4673 - s2_acc: 0.4416 - s3_acc: 0.6512 - student_loss_1: 1.6386 - student_loss_2: 1.1635 - student_loss_3: 0.6645 - distillation_loss_t_s1: 0.0191 - distillation_loss_s1_s2: 0.0146 - distillation_loss_s1_s3: 0.0166 - distillation_loss_t_s2: 0.0104 - distillation_loss_s2_s1: 0.0380 - distillation_loss_s2_s3: 0.0116 - distillation_loss_t_s3: 0.0129 - distillation_loss_s3_s1: 0.0390 - distillation_loss_s3_s2: 0.0095\n","Epoch 4/5\n","1563/1563 [==============================] - 447s 286ms/step - s1_acc: 0.5175 - s2_acc: 0.4844 - s3_acc: 0.6976 - student_loss_1: 1.2442 - student_loss_2: 1.0044 - student_loss_3: 0.5411 - distillation_loss_t_s1: 0.0160 - distillation_loss_s1_s2: 0.0124 - distillation_loss_s1_s3: 0.0123 - distillation_loss_t_s2: 0.0119 - distillation_loss_s2_s1: 0.0232 - distillation_loss_s2_s3: 0.0114 - distillation_loss_t_s3: 0.0132 - distillation_loss_s3_s1: 0.0229 - distillation_loss_s3_s2: 0.0100\n","Epoch 5/5\n","1563/1563 [==============================] - 447s 286ms/step - s1_acc: 0.5586 - s2_acc: 0.5191 - s3_acc: 0.7313 - student_loss_1: 1.1434 - student_loss_2: 0.8576 - student_loss_3: 0.4523 - distillation_loss_t_s1: 0.0141 - distillation_loss_s1_s2: 0.0115 - distillation_loss_s1_s3: 0.0094 - distillation_loss_t_s2: 0.0136 - distillation_loss_s2_s1: 0.0219 - distillation_loss_s2_s3: 0.0119 - distillation_loss_t_s3: 0.0136 - distillation_loss_s3_s1: 0.0202 - distillation_loss_s3_s2: 0.0106\n","313/313 [==============================] - 12s 36ms/step - s1_acc: 0.5781 - s2_acc: 0.5339 - s3_acc: 0.7463 - student_loss_1: 0.9914 - student_loss_2: 1.2979 - student_loss_3: 0.5440\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.5799269080162048,\n"," 0.5345500111579895,\n"," 0.7479192018508911,\n"," 1.1325149536132812,\n"," 0.9329811334609985,\n"," 0.6135732531547546]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"n6E8zCvSgMV_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637770608401,"user_tz":300,"elapsed":19486,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"63a6e119-b205-4e6f-a30f-0c618a341db4"},"source":["student1.save('/saved_models/peers1')\n","student2.save('/saved_models/peers2')\n","student3.save('/saved_models/peers3')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/peers1/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/peers2/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/peers3/assets\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCgZJQ6VvGp9","executionInfo":{"status":"ok","timestamp":1637770888178,"user_tz":300,"elapsed":20083,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"a58364e0-d856-4e9f-fac0-52f987497f23"},"source":["student1_test = tf.keras.models.load_model('/saved_models/peers1')\n","student2_test = tf.keras.models.load_model('/saved_models/peers2')\n","student3_test = tf.keras.models.load_model('/saved_models/peers3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile (\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","313/313 [==============================] - 12s 36ms/step - s1_acc: 0.6793 - s2_acc: 0.5711 - s3_acc: 0.8288 - student_loss_1: 0.9914 - student_loss_2: 1.2979 - student_loss_3: 0.5440\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.675000011920929,\n"," 0.5669000148773193,\n"," 0.8284000158309937,\n"," 1.1325149536132812,\n"," 0.9329811334609985,\n"," 0.6135732531547546]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"chbMxhQKxQ72","executionInfo":{"status":"ok","timestamp":1637773662181,"user_tz":300,"elapsed":75585,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"0c9f6d8f-5e8a-47cf-baf5-8ec8b37f0d82"},"source":["# Initialize and compile distiller\n","\n","student1_v2 = get_student1()\n","student2_v2 = get_student2()\n","student3_v2 = get_student3()\n","\n","distiller = Distiller(student1=student1_v2, student2=student2_v2, student3=student3_v2, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1563/1563 [==============================] - 455s 285ms/step - s1_acc: 0.2733 - s2_acc: 0.1669 - s3_acc: 0.3993 - student_loss_1: 103.5962 - student_loss_2: 2.5618 - student_loss_3: 1.3724 - distillation_loss_t_s1: 0.0229 - distillation_loss_s1_s2: 0.0473 - distillation_loss_s1_s3: 0.0321 - distillation_loss_t_s2: 0.0313 - distillation_loss_s2_s1: 0.7682 - distillation_loss_s2_s3: 0.0262 - distillation_loss_t_s3: 0.0093 - distillation_loss_s3_s1: 0.7558 - distillation_loss_s3_s2: 0.0334\n","Epoch 2/5\n","1563/1563 [==============================] - 446s 285ms/step - s1_acc: 0.3886 - s2_acc: 0.2838 - s3_acc: 0.5647 - student_loss_1: 2.5007 - student_loss_2: 1.5396 - student_loss_3: 0.8978 - distillation_loss_t_s1: 0.0211 - distillation_loss_s1_s2: 0.0166 - distillation_loss_s1_s3: 0.0208 - distillation_loss_t_s2: 0.0075 - distillation_loss_s2_s1: 0.0678 - distillation_loss_s2_s3: 0.0127 - distillation_loss_t_s3: 0.0115 - distillation_loss_s3_s1: 0.0695 - distillation_loss_s3_s2: 0.0092\n","Epoch 3/5\n","1563/1563 [==============================] - 444s 284ms/step - s1_acc: 0.4488 - s2_acc: 0.3589 - s3_acc: 0.6362 - student_loss_1: 1.7233 - student_loss_2: 1.3051 - student_loss_3: 0.6979 - distillation_loss_t_s1: 0.0184 - distillation_loss_s1_s2: 0.0143 - distillation_loss_s1_s3: 0.0162 - distillation_loss_t_s2: 0.0094 - distillation_loss_s2_s1: 0.0369 - distillation_loss_s2_s3: 0.0116 - distillation_loss_t_s3: 0.0125 - distillation_loss_s3_s1: 0.0382 - distillation_loss_s3_s2: 0.0098\n","Epoch 4/5\n","1563/1563 [==============================] - 445s 285ms/step - s1_acc: 0.4970 - s2_acc: 0.4109 - s3_acc: 0.6845 - student_loss_1: 1.3728 - student_loss_2: 1.1239 - student_loss_3: 0.5585 - distillation_loss_t_s1: 0.0162 - distillation_loss_s1_s2: 0.0126 - distillation_loss_s1_s3: 0.0129 - distillation_loss_t_s2: 0.0109 - distillation_loss_s2_s1: 0.0233 - distillation_loss_s2_s3: 0.0114 - distillation_loss_t_s3: 0.0130 - distillation_loss_s3_s1: 0.0238 - distillation_loss_s3_s2: 0.0102\n","Epoch 5/5\n","1563/1563 [==============================] - 446s 285ms/step - s1_acc: 0.5378 - s2_acc: 0.4531 - s3_acc: 0.7204 - student_loss_1: 1.0938 - student_loss_2: 0.9509 - student_loss_3: 0.4619 - distillation_loss_t_s1: 0.0144 - distillation_loss_s1_s2: 0.0114 - distillation_loss_s1_s3: 0.0102 - distillation_loss_t_s2: 0.0125 - distillation_loss_s2_s1: 0.0160 - distillation_loss_s2_s3: 0.0117 - distillation_loss_t_s3: 0.0134 - distillation_loss_s3_s1: 0.0150 - distillation_loss_s3_s2: 0.0105\n","313/313 [==============================] - 12s 35ms/step - s1_acc: 0.5582 - s2_acc: 0.4724 - s3_acc: 0.7364 - student_loss_1: 0.8997 - student_loss_2: 1.3065 - student_loss_3: 0.5859\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.5608307719230652,\n"," 0.47388461232185364,\n"," 0.7377307415008545,\n"," 0.8109766244888306,\n"," 1.2295775413513184,\n"," 0.5317625999450684]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ep2ZUD7Hzz34","executionInfo":{"status":"ok","timestamp":1637773988053,"user_tz":300,"elapsed":20989,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"f8752095-5914-4fe6-97a7-b463beee3a56"},"source":["# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 11s 35ms/step - s1_acc: 0.5635 - s2_acc: 0.4753 - s3_acc: 0.7390 - student_loss_1: 0.8997 - student_loss_2: 1.3065 - student_loss_3: 0.5859\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.565929651260376,\n"," 0.4767037034034729,\n"," 0.7402999997138977,\n"," 0.8109766244888306,\n"," 1.2295775413513184,\n"," 0.5317625999450684]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eURyvL5DxTG0","executionInfo":{"status":"ok","timestamp":1637774020993,"user_tz":300,"elapsed":20396,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"8c8fd0c2-545d-4dd2-b300-f402d5cfd164"},"source":["student1_v2.save('/saved_models/peers1_v2')\n","student2_v2.save('/saved_models/peers2_v2')\n","student3_v2.save('/saved_models/peers3_v2')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/peers1_v2/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/peers2_v2/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/peers3_v2/assets\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xzlxCUTexVFi","executionInfo":{"status":"ok","timestamp":1637774065977,"user_tz":300,"elapsed":21145,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"4c51c508-491e-4fb0-bce5-5688628b5e91"},"source":["student1_test = tf.keras.models.load_model('/saved_models/peers1_v2')\n","student2_test = tf.keras.models.load_model('/saved_models/peers2_v2')\n","student3_test = tf.keras.models.load_model('/saved_models/peers3_v2')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","313/313 [==============================] - 12s 37ms/step - s1_acc: 0.7017 - s2_acc: 0.5523 - s3_acc: 0.8112 - student_loss_1: 0.8997 - student_loss_2: 1.3065 - student_loss_3: 0.5859\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.6984999775886536,\n"," 0.550000011920929,\n"," 0.8070999979972839,\n"," 0.8109766244888306,\n"," 1.2295775413513184,\n"," 0.5317625999450684]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"k8HN3JwVMKZB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637706480885,"user_tz":300,"elapsed":4483810,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"1377edcb-b927-4bf4-a805-3800268605be"},"source":["# Initialize and compile distiller\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=10)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1563/1563 [==============================] - 464s 285ms/step - s1_acc: 0.1708 - s2_acc: 0.2323 - s3_acc: 0.4033 - student_loss_1: 79.3991 - student_loss_2: 2.4838 - student_loss_3: 1.3764 - distillation_loss_t_s1: 0.0222 - distillation_loss_s1_s2: 0.0495 - distillation_loss_s1_s3: 0.0321 - distillation_loss_t_s2: 0.0374 - distillation_loss_s2_s1: 0.6106 - distillation_loss_s2_s3: 0.0276 - distillation_loss_t_s3: 0.0094 - distillation_loss_s3_s1: 0.6047 - distillation_loss_s3_s2: 0.0393\n","Epoch 2/10\n","1563/1563 [==============================] - 444s 284ms/step - s1_acc: 0.2860 - s2_acc: 0.3738 - s3_acc: 0.5676 - student_loss_1: 2.3110 - student_loss_2: 1.4313 - student_loss_3: 0.8798 - distillation_loss_t_s1: 0.0209 - distillation_loss_s1_s2: 0.0166 - distillation_loss_s1_s3: 0.0210 - distillation_loss_t_s2: 0.0092 - distillation_loss_s2_s1: 0.0564 - distillation_loss_s2_s3: 0.0117 - distillation_loss_t_s3: 0.0118 - distillation_loss_s3_s1: 0.0585 - distillation_loss_s3_s2: 0.0087\n","Epoch 3/10\n","1563/1563 [==============================] - 444s 284ms/step - s1_acc: 0.3570 - s2_acc: 0.4425 - s3_acc: 0.6425 - student_loss_1: 1.6410 - student_loss_2: 1.2320 - student_loss_3: 0.6620 - distillation_loss_t_s1: 0.0185 - distillation_loss_s1_s2: 0.0147 - distillation_loss_s1_s3: 0.0170 - distillation_loss_t_s2: 0.0109 - distillation_loss_s2_s1: 0.0258 - distillation_loss_s2_s3: 0.0112 - distillation_loss_t_s3: 0.0128 - distillation_loss_s3_s1: 0.0273 - distillation_loss_s3_s2: 0.0096\n","Epoch 4/10\n","1563/1563 [==============================] - 444s 284ms/step - s1_acc: 0.4114 - s2_acc: 0.4897 - s3_acc: 0.6923 - student_loss_1: 1.5083 - student_loss_2: 1.0945 - student_loss_3: 0.5293 - distillation_loss_t_s1: 0.0164 - distillation_loss_s1_s2: 0.0129 - distillation_loss_s1_s3: 0.0136 - distillation_loss_t_s2: 0.0122 - distillation_loss_s2_s1: 0.0345 - distillation_loss_s2_s3: 0.0112 - distillation_loss_t_s3: 0.0133 - distillation_loss_s3_s1: 0.0351 - distillation_loss_s3_s2: 0.0103\n","Epoch 5/10\n","1563/1563 [==============================] - 444s 284ms/step - s1_acc: 0.4561 - s2_acc: 0.5277 - s3_acc: 0.7286 - student_loss_1: 1.1381 - student_loss_2: 0.9490 - student_loss_3: 0.4384 - distillation_loss_t_s1: 0.0142 - distillation_loss_s1_s2: 0.0115 - distillation_loss_s1_s3: 0.0103 - distillation_loss_t_s2: 0.0139 - distillation_loss_s2_s1: 0.0152 - distillation_loss_s2_s3: 0.0114 - distillation_loss_t_s3: 0.0136 - distillation_loss_s3_s1: 0.0142 - distillation_loss_s3_s2: 0.0109\n","Epoch 6/10\n","1563/1563 [==============================] - 445s 285ms/step - s1_acc: 0.4950 - s2_acc: 0.5616 - s3_acc: 0.7567 - student_loss_1: 0.9529 - student_loss_2: 0.7971 - student_loss_3: 0.3607 - distillation_loss_t_s1: 0.0131 - distillation_loss_s1_s2: 0.0115 - distillation_loss_s1_s3: 0.0088 - distillation_loss_t_s2: 0.0158 - distillation_loss_s2_s1: 0.0127 - distillation_loss_s2_s3: 0.0123 - distillation_loss_t_s3: 0.0139 - distillation_loss_s3_s1: 0.0100 - distillation_loss_s3_s2: 0.0117\n","Epoch 7/10\n","1563/1563 [==============================] - 444s 284ms/step - s1_acc: 0.5299 - s2_acc: 0.5941 - s3_acc: 0.7805 - student_loss_1: 0.7926 - student_loss_2: 0.6468 - student_loss_3: 0.2941 - distillation_loss_t_s1: 0.0127 - distillation_loss_s1_s2: 0.0120 - distillation_loss_s1_s3: 0.0076 - distillation_loss_t_s2: 0.0178 - distillation_loss_s2_s1: 0.0123 - distillation_loss_s2_s3: 0.0127 - distillation_loss_t_s3: 0.0141 - distillation_loss_s3_s1: 0.0080 - distillation_loss_s3_s2: 0.0123\n","Epoch 8/10\n","1563/1563 [==============================] - 443s 284ms/step - s1_acc: 0.5625 - s2_acc: 0.6252 - s3_acc: 0.8005 - student_loss_1: 0.6151 - student_loss_2: 0.5165 - student_loss_3: 0.2426 - distillation_loss_t_s1: 0.0128 - distillation_loss_s1_s2: 0.0122 - distillation_loss_s1_s3: 0.0069 - distillation_loss_t_s2: 0.0190 - distillation_loss_s2_s1: 0.0121 - distillation_loss_s2_s3: 0.0126 - distillation_loss_t_s3: 0.0143 - distillation_loss_s3_s1: 0.0068 - distillation_loss_s3_s2: 0.0123\n","Epoch 9/10\n","1563/1563 [==============================] - 442s 282ms/step - s1_acc: 0.5930 - s2_acc: 0.6543 - s3_acc: 0.8178 - student_loss_1: 0.5402 - student_loss_2: 0.4099 - student_loss_3: 0.1980 - distillation_loss_t_s1: 0.0132 - distillation_loss_s1_s2: 0.0125 - distillation_loss_s1_s3: 0.0065 - distillation_loss_t_s2: 0.0201 - distillation_loss_s2_s1: 0.0129 - distillation_loss_s2_s3: 0.0125 - distillation_loss_t_s3: 0.0143 - distillation_loss_s3_s1: 0.0069 - distillation_loss_s3_s2: 0.0121\n","Epoch 10/10\n","1563/1563 [==============================] - 441s 282ms/step - s1_acc: 0.6205 - s2_acc: 0.6809 - s3_acc: 0.8329 - student_loss_1: 0.4239 - student_loss_2: 0.3391 - student_loss_3: 0.1649 - distillation_loss_t_s1: 0.0135 - distillation_loss_s1_s2: 0.0121 - distillation_loss_s1_s3: 0.0059 - distillation_loss_t_s2: 0.0205 - distillation_loss_s2_s1: 0.0125 - distillation_loss_s2_s3: 0.0119 - distillation_loss_t_s3: 0.0143 - distillation_loss_s3_s1: 0.0061 - distillation_loss_s3_s2: 0.0116\n","313/313 [==============================] - 12s 35ms/step - s1_acc: 0.6339 - s2_acc: 0.6915 - s3_acc: 0.8397 - student_loss_1: 0.9074 - student_loss_2: 1.4221 - student_loss_3: 0.4851\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.6349921822547913,\n"," 0.690374493598938,\n"," 0.8398725390434265,\n"," 0.5361946225166321,\n"," 2.4807844161987305,\n"," 0.5392907857894897]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"1dolDvjWnYoP"},"source":[""],"execution_count":null,"outputs":[]}]}