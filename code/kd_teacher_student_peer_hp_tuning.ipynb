{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"kd_teacher_student_peer_hp_tuning_v2.ipynb","provenance":[{"file_id":"1Yjkh8BnLwDl_0ziqSWc7Q0wLnLUZWqRi","timestamp":1637636030674},{"file_id":"1XVvicESrmi2FwNTNCCjiTJC-JdqUCvL4","timestamp":1635606056154},{"file_id":"1ghEY2lIYJsUC-K63E8VvCjxk0IoKfpz3","timestamp":1635598814073},{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/vision/ipynb/knowledge_distillation.ipynb","timestamp":1635161502502}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"WrVvG0gsHSGe","executionInfo":{"status":"ok","timestamp":1637801702080,"user_tz":300,"elapsed":543,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"5945c336-8f0d-43a2-bb18-8ce42d3a18a1"},"source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","%cd '/content/drive/MyDrive/Project/'\n","%pwd"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1XSIbHWFizvrGifGPTwtsmagK2AS8ZE7n/Project\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/.shortcut-targets-by-id/1XSIbHWFizvrGifGPTwtsmagK2AS8ZE7n/Project'"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"pdHhiwRrMKY6"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LnoCIQFXTK3i"},"source":["np.random.seed(682)\n","tf.random.set_seed(682)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNRY26QEMKY8"},"source":["class Distiller(keras.Model):\n","\n","    def __init__(self, student1, student2, student3, teacher):\n","        super(Distiller, self).__init__()\n","        self.teacher = teacher\n","        self.student1 = student1\n","        self.student2 = student2\n","        self.student3 = student3\n","\n","    def compile(\n","        self,\n","        optimizer,\n","        metrics,\n","        student_loss_fn,\n","        distillation_loss_fn,\n","        alpha=0.1,\n","        beta=0.8,\n","        gamma=0.1,\n","        temperature=3,\n","    ):\n","        \"\"\" Configure the distiller.\n","\n","        Args:\n","            optimizer: Keras optimizer for the student weights\n","            metrics: Keras metrics for evaluation\n","            student_loss_fn: Loss function of difference between student\n","                predictions and ground-truth\n","            distillation_loss_fn: Loss function of difference between soft\n","                student predictions and soft teacher predictions\n","            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n","            temperature: Temperature for softening probability distributions.\n","                Larger temperature gives softer distributions.\n","        \"\"\"\n","        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n","        self.student_loss_fn = student_loss_fn\n","        self.distillation_loss_fn = distillation_loss_fn\n","        self.alpha = alpha\n","        self.beta = beta\n","        self.gamma = gamma\n","        self.temperature = temperature\n","\n","    def train_step(self, data):\n","        \n","        # Unpack data\n","        x, y = data\n","\n","        # Forward pass of teacher\n","        teacher_predictions = self.teacher(x, training=False)\n","\n","        with tf.GradientTape() as tape_student_1:\n","            \n","            # Forward pass of student\n","            student_predictions_1 = self.student1(x, training=True)\n","            student_predictions_2 = self.student2(x, training=False)\n","            student_predictions_3 = self.student3(x, training=False)\n","\n","            # Compute losses\n","            student_loss_1 = self.student_loss_fn(y, student_predictions_1)\n","            student_loss_2 = self.student_loss_fn(y, student_predictions_2)\n","            student_loss_3 = self.student_loss_fn(y, student_predictions_3)\n","\n","            # for student 1\n","            distillation_loss_t_s1 = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_1 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s1_s2 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_1 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_2 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s1_s3 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_1 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_3 / self.temperature, axis=1)\n","            )\n","\n","            loss_1 = self.alpha * student_loss_1 + self.beta * distillation_loss_t_s1 + self.gamma * (distillation_loss_s1_s2 + distillation_loss_s1_s3)\n","\n","        # Compute gradients\n","        trainable_vars_1 = self.student1.trainable_variables\n","        gradients_1 = tape_student_1.gradient(loss_1, trainable_vars_1)\n","        self.optimizer.apply_gradients(zip(gradients_1, trainable_vars_1))\n","        self.compiled_metrics._metrics[0].update_state(y, student_predictions_1)\n","        \n","\n","        with tf.GradientTape() as tape_student_2:\n","            \n","            # Forward pass of student\n","            student_predictions_1 = self.student1(x, training=False)\n","            student_predictions_2 = self.student2(x, training=True)\n","            student_predictions_3 = self.student3(x, training=False)\n","\n","            # Compute losses\n","            student_loss_1 = self.student_loss_fn(y, student_predictions_1)\n","            student_loss_2 = self.student_loss_fn(y, student_predictions_2)\n","            student_loss_3 = self.student_loss_fn(y, student_predictions_3)\n","            \n","            # for student 2\n","            distillation_loss_t_s2 = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_2 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s2_s1 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_2 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_1 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s2_s3 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_2 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_3 / self.temperature, axis=1)\n","            )\n","\n","            loss_2 = self.alpha * student_loss_2 + self.beta * distillation_loss_t_s2 + self.gamma * (distillation_loss_s2_s1 + distillation_loss_s2_s3)\n","\n","        trainable_vars_2 = self.student2.trainable_variables\n","        gradients_2 = tape_student_2.gradient(loss_2, trainable_vars_2)\n","\n","        self.optimizer.apply_gradients(zip(gradients_2, trainable_vars_2))\n","\n","        self.compiled_metrics._metrics[1].update_state(y, student_predictions_2)\n","            \n","\n","        with tf.GradientTape() as tape_student_3:\n","            \n","            # Forward pass of student\n","            student_predictions_1 = self.student1(x, training=False)\n","            student_predictions_2 = self.student2(x, training=False)\n","            student_predictions_3 = self.student3(x, training=True)\n","\n","            # Compute losses\n","            student_loss_1 = self.student_loss_fn(y, student_predictions_1)\n","            student_loss_2 = self.student_loss_fn(y, student_predictions_2)\n","            student_loss_3 = self.student_loss_fn(y, student_predictions_3)\n","\n","            # for student 3\n","            distillation_loss_t_s3 = self.distillation_loss_fn(\n","                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_3 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s3_s1 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_3 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_1 / self.temperature, axis=1)\n","            )\n","            distillation_loss_s3_s2 = self.distillation_loss_fn(\n","                tf.nn.softmax(student_predictions_3 / self.temperature, axis=1),\n","                tf.nn.softmax(student_predictions_2 / self.temperature, axis=1)\n","            )\n","\n","            loss_3 = self.alpha * student_loss_3 + self.beta * distillation_loss_t_s3 + self.gamma * (distillation_loss_s3_s1 + distillation_loss_s3_s2)\n","\n","        trainable_vars_3 = self.student3.trainable_variables\n","        gradients_3 = tape_student_3.gradient(loss_3, trainable_vars_3)\n","\n","        # Update weights\n","        self.optimizer.apply_gradients(zip(gradients_3, trainable_vars_3))\n","\n","        # Update the metrics configured in `compile()`.     \n","        self.compiled_metrics._metrics[2].update_state(y, student_predictions_3)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.compiled_metrics._metrics}\n","\n","        results.update (\n","            {\"student_loss_1\": student_loss_1,\n","             \"student_loss_2\": student_loss_2,\n","             \"student_loss_3\": student_loss_3,\n","             \"distillation_loss_t_s1\": distillation_loss_t_s1,\n","             \"distillation_loss_s1_s2\": distillation_loss_s1_s2,\n","             \"distillation_loss_s1_s3\": distillation_loss_s1_s3,\n","             \"distillation_loss_t_s2\": distillation_loss_t_s2,\n","             \"distillation_loss_s2_s1\": distillation_loss_s2_s1,\n","             \"distillation_loss_s2_s3\": distillation_loss_s2_s3,\n","             \"distillation_loss_t_s3\": distillation_loss_t_s3,\n","             \"distillation_loss_s3_s1\": distillation_loss_s3_s1,\n","             \"distillation_loss_s3_s2\": distillation_loss_s3_s2}\n","        )\n","\n","        return results\n","\n","\n","    def test_step(self, data):\n","        # Unpack the data\n","        x, y = data\n","\n","        # Compute predictions\n","        y_prediction_1 = self.student1(x, training=False)\n","        y_prediction_2 = self.student2(x, training=False)\n","        y_prediction_3 = self.student3(x, training=False)\n","\n","        # Calculate the loss\n","        student_loss_1 = self.student_loss_fn(y, y_prediction_1)\n","        student_loss_2 = self.student_loss_fn(y, y_prediction_2)\n","        student_loss_3 = self.student_loss_fn(y, y_prediction_3)\n","\n","        # Update the metrics.\n","        self.compiled_metrics._metrics[0].update_state(y, y_prediction_1)\n","        self.compiled_metrics._metrics[1].update_state(y, y_prediction_2)\n","        self.compiled_metrics._metrics[2].update_state(y, y_prediction_3)\n","\n","        # Return a dict of performance\n","        results = {m.name: m.result() for m in self.compiled_metrics._metrics}\n","\n","        results.update({\"student_loss_1\": student_loss_1,\n","             \"student_loss_2\": student_loss_2,\n","             \"student_loss_3\": student_loss_3})\n","\n","        return results\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sdQr6q3igRX5"},"source":["teacher = tf.keras.models.load_model('/saved_models/resnet50cifar')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-uiYUJnggJp"},"source":["# Student 3\n","\n","def get_student3():\n","\n","  def preprocess_image_input(input_images):\n","    input_images = tf.cast(input_images, 'float32')\n","    output_ims = tf.keras.applications.mobilenet.preprocess_input(input_images)\n","    return output_ims\n","\n","  class Preprocess(tf.keras.layers.Layer):\n","      def __init__(self):\n","          super(Preprocess, self).__init__()\n","\n","      def call(self, inputs):\n","          return preprocess_image_input(inputs)\n","\n","  student_mobile = tf.keras.applications.MobileNet(\n","      input_shape=(224, 224, 3),\n","      alpha=1.0,\n","      depth_multiplier=1,\n","      dropout=0.001,\n","      include_top=True,\n","      weights=None,\n","      input_tensor=None,\n","      pooling=None,\n","      classes=10,\n","      classifier_activation=None\n","  )\n","\n","  inputs = tf.keras.layers.Input(shape=(32,32,3))\n","  resize = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n","  pre_process = Preprocess()(resize)\n","  resnet_extractor = student_mobile(pre_process)\n","  student = tf.keras.Model(inputs=inputs, outputs = resnet_extractor)\n","  return student\n","\n","student3 = get_student3()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w5vDZ9Cfgmmk"},"source":["# Student 2\n","\n","def get_student2():\n","\n","  # Import necessary components to build LeNet\n","  from keras.models import Sequential\n","  from keras.layers.core import Dense, Activation, Flatten\n","  from keras.layers.convolutional import Conv2D, MaxPooling2D\n","  from keras.regularizers import l2\n","\n","  def lenet_model(img_shape=(32, 32, 3), n_classes=10, l2_reg=0.,\n","    weights=None):\n","\n","    # Initialize model\n","    lenet = Sequential()\n","\n","    # 2 sets of CRP (Convolution, RELU, Pooling)\n","    lenet.add(Conv2D(20, (5, 5), padding=\"same\",\n","      input_shape=img_shape, kernel_regularizer=l2(l2_reg)))\n","    lenet.add(Activation(\"relu\"))\n","    lenet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","    lenet.add(Conv2D(50, (5, 5), padding=\"same\",\n","      kernel_regularizer=l2(l2_reg)))\n","    lenet.add(Activation(\"relu\"))\n","    lenet.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","    # Fully connected layers (w/ RELU)\n","    lenet.add(Flatten())\n","    lenet.add(Dense(500, kernel_regularizer=l2(l2_reg)))\n","    lenet.add(Activation(\"relu\"))\n","\n","    # Softmax (for classification)\n","    lenet.add(Dense(n_classes, kernel_regularizer=l2(l2_reg)))\n","    # lenet.add(Activation(\"softmax\"))\n","\n","    if weights is not None:\n","      lenet.load_weights(weights)\n","\n","    # Return the constructed network\n","    return lenet\n","\n","  # Create the student\n","  student = lenet_model()\n","  return student\n","\n","student2 = get_student2()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNKaodNwgvkW"},"source":["# Student 1\n","\n","def get_student1():\n","\n","  from keras.models import Sequential\n","  from keras.layers.core import Dense, Dropout, Activation, Flatten\n","  from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n","  from keras.layers import BatchNormalization\n","  from keras.regularizers import l2\n","\n","  def alexnet_model(img_shape=(32, 32, 3), n_classes=10, l2_reg=0., weights=None):\n","\n","    # Initialize model\n","    alexnet = Sequential()\n","\n","    # Layer 1\n","    alexnet.add(Conv2D(96, (11, 11), input_shape=img_shape,\n","      padding='same', kernel_regularizer=l2(l2_reg)))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # Layer 2\n","    alexnet.add(Conv2D(256, (5, 5), padding='same'))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # Layer 3\n","    alexnet.add(ZeroPadding2D((1, 1)))\n","    alexnet.add(Conv2D(512, (3, 3), padding='same'))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # Layer 4\n","    alexnet.add(ZeroPadding2D((1, 1)))\n","    alexnet.add(Conv2D(1024, (3, 3), padding='same'))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","\n","    # Layer 5\n","    alexnet.add(ZeroPadding2D((1, 1)))\n","    alexnet.add(Conv2D(1024, (3, 3), padding='same'))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    # Layer 6\n","    alexnet.add(Flatten())\n","    alexnet.add(Dense(3072))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(Dropout(0.5))\n","\n","    # Layer 7\n","    alexnet.add(Dense(4096))\n","    alexnet.add(BatchNormalization())\n","    alexnet.add(Activation('relu'))\n","    alexnet.add(Dropout(0.5))\n","\n","    # Layer 8\n","    alexnet.add(Dense(n_classes))\n","\n","    if weights is not None:\n","      alexnet.load_weights(weights)\n","\n","    return alexnet\n","\n","  # Create the student\n","  student = alexnet_model()\n","  return student\n","\n","student1 = get_student1()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nml9yy4rMKZA"},"source":["# Prepare the train and test dataset.\n","batch_size = 64\n","\n","(x_train, y_train) , (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","# # x_val = x_train[0:10000]\n","# # y_val = y_train[0:10000]\n","# x_train = x_train[10000:50000]\n","# y_train = y_train[10000:50000]\n","\n","# from sklearn.model_selection import train_test_split\n","# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=10000, random_state=682)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1dolDvjWnYoP","outputId":"8268ddbf-b359-4c15-e9e2-4ab55820042b"},"source":["# Initialize and compile distiller\n","\n","beta = 0.6\n","\n","print(f\"alpha: 0.1; beta: {beta}; gamma: {1 - 0.1 - beta}\")\n","\n","student1 = get_student1()\n","student2 = get_student2()\n","student3 = get_student3()\n","\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    beta=beta,\n","    gamma=(1 - 0.1 - beta),\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_val, y_val)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)\n","\n","student1.save('/saved_models/h1_s1')\n","student2.save('/saved_models/h1_s2')\n","student3.save('/saved_models/h1_s3')\n","\n","student1_test = tf.keras.models.load_model('/saved_models/h1_s1')\n","student2_test = tf.keras.models.load_model('/saved_models/h1_s2')\n","student3_test = tf.keras.models.load_model('/saved_models/h1_s3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile (\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)\n","\n","print()\n","print()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["alpha: 0.1; beta: 0.6; gamma: 0.30000000000000004\n","Epoch 1/5\n","938/938 [==============================] - 284s 283ms/step - s1_acc: 0.2428 - s2_acc: 0.1204 - s3_acc: 0.3289 - student_loss_1: 213.5090 - student_loss_2: 2.6233 - student_loss_3: 1.6088 - distillation_loss_t_s1: 0.0210 - distillation_loss_s1_s2: 0.0455 - distillation_loss_s1_s3: 0.0237 - distillation_loss_t_s2: 0.0280 - distillation_loss_s2_s1: 1.2780 - distillation_loss_s2_s3: 0.0184 - distillation_loss_t_s3: 0.0102 - distillation_loss_s3_s1: 1.2487 - distillation_loss_s3_s2: 0.0329\n","Epoch 2/5\n","938/938 [==============================] - 266s 283ms/step - s1_acc: 0.3339 - s2_acc: 0.1589 - s3_acc: 0.4876 - student_loss_1: 5.9992 - student_loss_2: 2.1110 - student_loss_3: 1.1614 - distillation_loss_t_s1: 0.0230 - distillation_loss_s1_s2: 0.0197 - distillation_loss_s1_s3: 0.0344 - distillation_loss_t_s2: 0.0036 - distillation_loss_s2_s1: 0.2828 - distillation_loss_s2_s3: 0.0277 - distillation_loss_t_s3: 0.0134 - distillation_loss_s3_s1: 0.2683 - distillation_loss_s3_s2: 0.0129\n","Epoch 3/5\n","938/938 [==============================] - 265s 283ms/step - s1_acc: 0.3889 - s2_acc: 0.2063 - s3_acc: 0.5592 - student_loss_1: 2.2664 - student_loss_2: 1.7243 - student_loss_3: 0.8929 - distillation_loss_t_s1: 0.0202 - distillation_loss_s1_s2: 0.0162 - distillation_loss_s1_s3: 0.0192 - distillation_loss_t_s2: 0.0062 - distillation_loss_s2_s1: 0.0604 - distillation_loss_s2_s3: 0.0132 - distillation_loss_t_s3: 0.0118 - distillation_loss_s3_s1: 0.0608 - distillation_loss_s3_s2: 0.0101\n","Epoch 4/5\n","938/938 [==============================] - 265s 283ms/step - s1_acc: 0.4330 - s2_acc: 0.2591 - s3_acc: 0.6085 - student_loss_1: 3.8879 - student_loss_2: 1.5299 - student_loss_3: 0.7644 - distillation_loss_t_s1: 0.0201 - distillation_loss_s1_s2: 0.0158 - distillation_loss_s1_s3: 0.0194 - distillation_loss_t_s2: 0.0086 - distillation_loss_s2_s1: 0.1749 - distillation_loss_s2_s3: 0.0145 - distillation_loss_t_s3: 0.0134 - distillation_loss_s3_s1: 0.1772 - distillation_loss_s3_s2: 0.0110\n","Epoch 5/5\n","938/938 [==============================] - 265s 283ms/step - s1_acc: 0.4659 - s2_acc: 0.3039 - s3_acc: 0.6465 - student_loss_1: 1.8878 - student_loss_2: 1.3123 - student_loss_3: 0.6166 - distillation_loss_t_s1: 0.0185 - distillation_loss_s1_s2: 0.0145 - distillation_loss_s1_s3: 0.0153 - distillation_loss_t_s2: 0.0105 - distillation_loss_s2_s1: 0.0479 - distillation_loss_s2_s3: 0.0120 - distillation_loss_t_s3: 0.0135 - distillation_loss_s3_s1: 0.0491 - distillation_loss_s3_s2: 0.0107\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.4833 - s2_acc: 0.3297 - s3_acc: 0.6660 - student_loss_1: 1.3296 - student_loss_2: 1.4496 - student_loss_3: 0.7529\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.4874 - s2_acc: 0.3391 - s3_acc: 0.6712 - student_loss_1: 1.3439 - student_loss_2: 1.4793 - student_loss_3: 0.7628\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h1_s1/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h1_s2/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h1_s3/assets\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","313/313 [==============================] - 11s 35ms/step - s1_acc: 0.5559 - s2_acc: 0.4794 - s3_acc: 0.7496 - student_loss_1: 1.3439 - student_loss_2: 1.4793 - student_loss_3: 0.7628\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"zsZSxVlG2G2t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637792141032,"user_tz":300,"elapsed":1421720,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"4b31e766-8158-4ef6-8a93-78186daf83e1"},"source":["beta = 0.7\n","\n","print(f\"alpha: 0.1; beta: {beta}; gamma: {1 - 0.1 - beta}\")\n","\n","student1 = get_student1()\n","student2 = get_student2()\n","student3 = get_student3()\n","\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    beta=beta,\n","    gamma=(1 - 0.1 - beta),\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_val, y_val)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)\n","\n","student1.save('/saved_models/h2_s1')\n","student2.save('/saved_models/h2_s2')\n","student3.save('/saved_models/h2_s3')\n","\n","student1_test = tf.keras.models.load_model('/saved_models/h2_s1')\n","student2_test = tf.keras.models.load_model('/saved_models/h2_s2')\n","student3_test = tf.keras.models.load_model('/saved_models/h2_s3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)\n","\n","print()\n","print()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["alpha: 0.1; beta: 0.7; gamma: 0.20000000000000007\n","Epoch 1/5\n","938/938 [==============================] - 275s 283ms/step - s1_acc: 0.2164 - s2_acc: 0.1085 - s3_acc: 0.3182 - student_loss_1: 183.0199 - student_loss_2: 3.0867 - student_loss_3: 1.6197 - distillation_loss_t_s1: 0.0212 - distillation_loss_s1_s2: 0.0604 - distillation_loss_s1_s3: 0.0252 - distillation_loss_t_s2: 0.0424 - distillation_loss_s2_s1: 1.1849 - distillation_loss_s2_s3: 0.0220 - distillation_loss_t_s3: 0.0088 - distillation_loss_s3_s1: 1.1639 - distillation_loss_s3_s2: 0.0484\n","Epoch 2/5\n","938/938 [==============================] - 265s 282ms/step - s1_acc: 0.2976 - s2_acc: 0.1043 - s3_acc: 0.4731 - student_loss_1: 3.1161 - student_loss_2: 2.2900 - student_loss_3: 1.1254 - distillation_loss_t_s1: 0.0195 - distillation_loss_s1_s2: 0.0195 - distillation_loss_s1_s3: 0.0219 - distillation_loss_t_s2: 4.9564e-04 - distillation_loss_s2_s1: 0.0843 - distillation_loss_s2_s3: 0.0172 - distillation_loss_t_s3: 0.0101 - distillation_loss_s3_s1: 0.0816 - distillation_loss_s3_s2: 0.0125\n","Epoch 3/5\n","938/938 [==============================] - 265s 282ms/step - s1_acc: 0.3528 - s2_acc: 0.1094 - s3_acc: 0.5494 - student_loss_1: 3.1317 - student_loss_2: 2.2190 - student_loss_3: 0.8968 - distillation_loss_t_s1: 0.0191 - distillation_loss_s1_s2: 0.0191 - distillation_loss_s1_s3: 0.0198 - distillation_loss_t_s2: 0.0011 - distillation_loss_s2_s1: 0.1120 - distillation_loss_s2_s3: 0.0165 - distillation_loss_t_s3: 0.0116 - distillation_loss_s3_s1: 0.1042 - distillation_loss_s3_s2: 0.0142\n","Epoch 4/5\n","938/938 [==============================] - 265s 283ms/step - s1_acc: 0.3954 - s2_acc: 0.1486 - s3_acc: 0.6038 - student_loss_1: 1.6206 - student_loss_2: 1.6792 - student_loss_3: 0.7220 - distillation_loss_t_s1: 0.0179 - distillation_loss_s1_s2: 0.0147 - distillation_loss_s1_s3: 0.0171 - distillation_loss_t_s2: 0.0066 - distillation_loss_s2_s1: 0.0247 - distillation_loss_s2_s3: 0.0132 - distillation_loss_t_s3: 0.0124 - distillation_loss_s3_s1: 0.0261 - distillation_loss_s3_s2: 0.0115\n","Epoch 5/5\n","938/938 [==============================] - 265s 283ms/step - s1_acc: 0.4336 - s2_acc: 0.2087 - s3_acc: 0.6458 - student_loss_1: 1.5611 - student_loss_2: 1.4370 - student_loss_3: 0.6020 - distillation_loss_t_s1: 0.0178 - distillation_loss_s1_s2: 0.0139 - distillation_loss_s1_s3: 0.0157 - distillation_loss_t_s2: 0.0084 - distillation_loss_s2_s1: 0.0261 - distillation_loss_s2_s3: 0.0126 - distillation_loss_t_s3: 0.0132 - distillation_loss_s3_s1: 0.0273 - distillation_loss_s3_s2: 0.0113\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.4521 - s2_acc: 0.2418 - s3_acc: 0.6650 - student_loss_1: 2.6998 - student_loss_2: 1.5564 - student_loss_3: 0.7932\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.4547 - s2_acc: 0.2544 - s3_acc: 0.6694 - student_loss_1: 2.6890 - student_loss_2: 1.5745 - student_loss_3: 0.7853\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h2_s1/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h2_s2/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h2_s3/assets\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","313/313 [==============================] - 12s 35ms/step - s1_acc: 0.4964 - s2_acc: 0.4408 - s3_acc: 0.7388 - student_loss_1: 2.6890 - student_loss_2: 1.5745 - student_loss_3: 0.7853\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZOezg502AMkj","executionInfo":{"elapsed":1384982,"status":"ok","timestamp":1637683085632,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"},"user_tz":300},"outputId":"315d12a1-ffa2-4d90-957f-b2abca98255b"},"source":["beta = 0.7\n","\n","print(f\"alpha: 0.1; beta: {beta}; gamma: {1 - 0.1 - beta}\")\n","\n","student1 = get_student1()\n","student2 = get_student2()\n","student3 = get_student3()\n","\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    beta=beta,\n","    gamma=(1 - 0.1 - beta),\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_val, y_val)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)\n","\n","student1.save('/saved_models/h2_s1')\n","student2.save('/saved_models/h2_s2')\n","student3.save('/saved_models/h2_s3')\n","\n","student1_test = tf.keras.models.load_model('/saved_models/h2_s1')\n","student2_test = tf.keras.models.load_model('/saved_models/h2_s2')\n","student3_test = tf.keras.models.load_model('/saved_models/h2_s3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)\n","\n","print()\n","print()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["alpha: 0.1; beta: 0.7; gamma: 0.20000000000000007\n","Epoch 1/5\n","938/938 [==============================] - 283s 282ms/step - s1_acc: 0.1554 - s2_acc: 0.1776 - s3_acc: 0.3340 - student_loss_1: 176.3997 - student_loss_2: 2.4956 - student_loss_3: 1.5691 - distillation_loss_t_s1: 0.0229 - distillation_loss_s1_s2: 0.0431 - distillation_loss_s1_s3: 0.0281 - distillation_loss_t_s2: 0.0295 - distillation_loss_s2_s1: 0.9445 - distillation_loss_s2_s3: 0.0206 - distillation_loss_t_s3: 0.0089 - distillation_loss_s3_s1: 0.9366 - distillation_loss_s3_s2: 0.0330\n","Epoch 2/5\n","938/938 [==============================] - 263s 281ms/step - s1_acc: 0.2303 - s2_acc: 0.3011 - s3_acc: 0.4938 - student_loss_1: 3.5321 - student_loss_2: 1.6246 - student_loss_3: 1.0880 - distillation_loss_t_s1: 0.0211 - distillation_loss_s1_s2: 0.0168 - distillation_loss_s1_s3: 0.0226 - distillation_loss_t_s2: 0.0080 - distillation_loss_s2_s1: 0.1093 - distillation_loss_s2_s3: 0.0128 - distillation_loss_t_s3: 0.0111 - distillation_loss_s3_s1: 0.1109 - distillation_loss_s3_s2: 0.0083\n","Epoch 3/5\n","938/938 [==============================] - 263s 280ms/step - s1_acc: 0.2880 - s2_acc: 0.3692 - s3_acc: 0.5669 - student_loss_1: 2.1344 - student_loss_2: 1.4077 - student_loss_3: 0.8504 - distillation_loss_t_s1: 0.0204 - distillation_loss_s1_s2: 0.0160 - distillation_loss_s1_s3: 0.0201 - distillation_loss_t_s2: 0.0099 - distillation_loss_s2_s1: 0.0384 - distillation_loss_s2_s3: 0.0123 - distillation_loss_t_s3: 0.0122 - distillation_loss_s3_s1: 0.0400 - distillation_loss_s3_s2: 0.0092\n","Epoch 4/5\n","938/938 [==============================] - 263s 281ms/step - s1_acc: 0.3346 - s2_acc: 0.4201 - s3_acc: 0.6194 - student_loss_1: 1.7710 - student_loss_2: 1.2161 - student_loss_3: 0.6849 - distillation_loss_t_s1: 0.0186 - distillation_loss_s1_s2: 0.0154 - distillation_loss_s1_s3: 0.0175 - distillation_loss_t_s2: 0.0118 - distillation_loss_s2_s1: 0.0256 - distillation_loss_s2_s3: 0.0119 - distillation_loss_t_s3: 0.0128 - distillation_loss_s3_s1: 0.0267 - distillation_loss_s3_s2: 0.0102\n","Epoch 5/5\n","938/938 [==============================] - 263s 280ms/step - s1_acc: 0.3658 - s2_acc: 0.4644 - s3_acc: 0.6603 - student_loss_1: 1.7827 - student_loss_2: 1.0333 - student_loss_3: 0.5733 - distillation_loss_t_s1: 0.0172 - distillation_loss_s1_s2: 0.0149 - distillation_loss_s1_s3: 0.0153 - distillation_loss_t_s2: 0.0137 - distillation_loss_s2_s1: 0.0364 - distillation_loss_s2_s3: 0.0122 - distillation_loss_t_s3: 0.0137 - distillation_loss_s3_s1: 0.0363 - distillation_loss_s3_s2: 0.0111\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.3881 - s2_acc: 0.4849 - s3_acc: 0.6786 - student_loss_1: 1.8535 - student_loss_2: 1.3937 - student_loss_3: 0.7960\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.3943 - s2_acc: 0.4876 - s3_acc: 0.6817 - student_loss_1: 1.8822 - student_loss_2: 1.4121 - student_loss_3: 0.8120\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"PTEEU42a2KHI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637806521483,"user_tz":300,"elapsed":1758414,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"e1b17f5c-9c22-4218-bef6-6e8c5113c59b"},"source":["beta = 0.8\n","print(f\"alpha: 0.1; beta: {beta}; gamma: {1 - 0.1 - beta}\")\n","\n","# student1 = get_student1()\n","# student2 = get_student2()\n","# student3 = get_student3()\n","\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    beta=beta,\n","    gamma=(1 - 0.1 - beta),\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","# distiller.evaluate(x_val, y_val)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)\n","\n","student1.save('/saved_models/h3_s1')\n","student2.save('/saved_models/h3_s2')\n","student3.save('/saved_models/h3_s3')\n","\n","student1_test = tf.keras.models.load_model('/saved_models/h3_s1')\n","student2_test = tf.keras.models.load_model('/saved_models/h3_s2')\n","student3_test = tf.keras.models.load_model('/saved_models/h3_s3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)\n","\n","print()\n","print()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["alpha: 0.1; beta: 0.8; gamma: 0.09999999999999998\n","Epoch 1/5\n","1563/1563 [==============================] - 465s 289ms/step - s1_acc: 0.2849 - s2_acc: 0.2603 - s3_acc: 0.4046 - student_loss_1: 99.9419 - student_loss_2: 2.2838 - student_loss_3: 1.3760 - distillation_loss_t_s1: 0.0211 - distillation_loss_s1_s2: 0.0478 - distillation_loss_s1_s3: 0.0286 - distillation_loss_t_s2: 0.0372 - distillation_loss_s2_s1: 0.8122 - distillation_loss_s2_s3: 0.0248 - distillation_loss_t_s3: 0.0096 - distillation_loss_s3_s1: 0.8040 - distillation_loss_s3_s2: 0.0358\n","Epoch 2/5\n","1563/1563 [==============================] - 452s 289ms/step - s1_acc: 0.4045 - s2_acc: 0.4026 - s3_acc: 0.5686 - student_loss_1: 2.1384 - student_loss_2: 1.2921 - student_loss_3: 0.8820 - distillation_loss_t_s1: 0.0201 - distillation_loss_s1_s2: 0.0155 - distillation_loss_s1_s3: 0.0191 - distillation_loss_t_s2: 0.0095 - distillation_loss_s2_s1: 0.0473 - distillation_loss_s2_s3: 0.0116 - distillation_loss_t_s3: 0.0117 - distillation_loss_s3_s1: 0.0488 - distillation_loss_s3_s2: 0.0084\n","Epoch 3/5\n","1563/1563 [==============================] - 451s 288ms/step - s1_acc: 0.4704 - s2_acc: 0.4634 - s3_acc: 0.6410 - student_loss_1: 2.4122 - student_loss_2: 1.1006 - student_loss_3: 0.6744 - distillation_loss_t_s1: 0.0180 - distillation_loss_s1_s2: 0.0139 - distillation_loss_s1_s3: 0.0154 - distillation_loss_t_s2: 0.0112 - distillation_loss_s2_s1: 0.0958 - distillation_loss_s2_s3: 0.0112 - distillation_loss_t_s3: 0.0128 - distillation_loss_s3_s1: 0.0969 - distillation_loss_s3_s2: 0.0092\n","Epoch 4/5\n","1563/1563 [==============================] - 449s 287ms/step - s1_acc: 0.5189 - s2_acc: 0.5057 - s3_acc: 0.6900 - student_loss_1: 1.7445 - student_loss_2: 0.9384 - student_loss_3: 0.5456 - distillation_loss_t_s1: 0.0152 - distillation_loss_s1_s2: 0.0120 - distillation_loss_s1_s3: 0.0117 - distillation_loss_t_s2: 0.0126 - distillation_loss_s2_s1: 0.0577 - distillation_loss_s2_s3: 0.0112 - distillation_loss_t_s3: 0.0132 - distillation_loss_s3_s1: 0.0572 - distillation_loss_s3_s2: 0.0098\n","Epoch 5/5\n","1563/1563 [==============================] - 447s 286ms/step - s1_acc: 0.5588 - s2_acc: 0.5418 - s3_acc: 0.7257 - student_loss_1: 0.9485 - student_loss_2: 0.7795 - student_loss_3: 0.4535 - distillation_loss_t_s1: 0.0137 - distillation_loss_s1_s2: 0.0112 - distillation_loss_s1_s3: 0.0092 - distillation_loss_t_s2: 0.0142 - distillation_loss_s2_s1: 0.0134 - distillation_loss_s2_s3: 0.0115 - distillation_loss_t_s3: 0.0135 - distillation_loss_s3_s1: 0.0114 - distillation_loss_s3_s2: 0.0103\n","313/313 [==============================] - 12s 37ms/step - s1_acc: 0.5774 - s2_acc: 0.5572 - s3_acc: 0.7408 - student_loss_1: 1.0990 - student_loss_2: 1.2737 - student_loss_3: 0.6321\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h3_s1/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h3_s2/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h3_s3/assets\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","313/313 [==============================] - 13s 37ms/step - s1_acc: 0.6472 - s2_acc: 0.5754 - s3_acc: 0.7888 - student_loss_1: 1.0990 - student_loss_2: 1.2737 - student_loss_3: 0.6321\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdz8TM3ajfzd","executionInfo":{"status":"ok","timestamp":1637801518967,"user_tz":300,"elapsed":23410,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"34e1e9b5-b30c-4248-d7c0-9a4088ee0580"},"source":["student1_test = tf.keras.models.load_model('/saved_models/h3_s1')\n","student2_test = tf.keras.models.load_model('/saved_models/h3_s2')\n","student3_test = tf.keras.models.load_model('/saved_models/h3_s3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)\n","\n","print()\n","print()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","313/313 [==============================] - 13s 38ms/step - s1_acc: 0.5521 - s2_acc: 0.5010 - s3_acc: 0.7161 - student_loss_1: 1.3726 - student_loss_2: 1.4388 - student_loss_3: 0.8551\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uVkWJRTilOpx","executionInfo":{"status":"ok","timestamp":1637803826518,"user_tz":300,"elapsed":1908435,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"915db999-08b3-48f8-fdd1-d5aef673225a"},"source":["beta = 0.8\n","print(f\"alpha: 0.1; beta: {beta}; gamma: {1 - 0.1 - beta}\")\n","\n","# student1 = get_student1()\n","# student2 = get_student2()\n","# student3 = get_student3()\n","\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    beta=beta,\n","    gamma=(1 - 0.1 - beta),\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_val, y_val)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)\n","\n","student1.save('/saved_models/h3_s1')\n","student2.save('/saved_models/h3_s2')\n","student3.save('/saved_models/h3_s3')\n","\n","student1_test = tf.keras.models.load_model('/saved_models/h3_s1')\n","student2_test = tf.keras.models.load_model('/saved_models/h3_s2')\n","student3_test = tf.keras.models.load_model('/saved_models/h3_s3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)\n","\n","print()\n","print()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["alpha: 0.1; beta: 0.8; gamma: 0.09999999999999998\n","Epoch 1/5\n","1250/1250 [==============================] - 375s 289ms/step - s1_acc: 0.2614 - s2_acc: 0.1621 - s3_acc: 0.3784 - student_loss_1: 84.3195 - student_loss_2: 2.7196 - student_loss_3: 1.4489 - distillation_loss_t_s1: 0.0223 - distillation_loss_s1_s2: 0.0539 - distillation_loss_s1_s3: 0.0289 - distillation_loss_t_s2: 0.0388 - distillation_loss_s2_s1: 1.1658 - distillation_loss_s2_s3: 0.0245 - distillation_loss_t_s3: 0.0093 - distillation_loss_s3_s1: 1.1674 - distillation_loss_s3_s2: 0.0418\n","Epoch 2/5\n","1250/1250 [==============================] - 361s 289ms/step - s1_acc: 0.3698 - s2_acc: 0.2632 - s3_acc: 0.5397 - student_loss_1: 2.2843 - student_loss_2: 1.5868 - student_loss_3: 0.9627 - distillation_loss_t_s1: 0.0207 - distillation_loss_s1_s2: 0.0164 - distillation_loss_s1_s3: 0.0212 - distillation_loss_t_s2: 0.0071 - distillation_loss_s2_s1: 0.0505 - distillation_loss_s2_s3: 0.0139 - distillation_loss_t_s3: 0.0114 - distillation_loss_s3_s1: 0.0521 - distillation_loss_s3_s2: 0.0092\n","Epoch 3/5\n","1250/1250 [==============================] - 361s 289ms/step - s1_acc: 0.4334 - s2_acc: 0.3444 - s3_acc: 0.6140 - student_loss_1: 1.8794 - student_loss_2: 1.2903 - student_loss_3: 0.7461 - distillation_loss_t_s1: 0.0188 - distillation_loss_s1_s2: 0.0147 - distillation_loss_s1_s3: 0.0177 - distillation_loss_t_s2: 0.0095 - distillation_loss_s2_s1: 0.0408 - distillation_loss_s2_s3: 0.0125 - distillation_loss_t_s3: 0.0127 - distillation_loss_s3_s1: 0.0420 - distillation_loss_s3_s2: 0.0096\n","Epoch 4/5\n","1250/1250 [==============================] - 361s 289ms/step - s1_acc: 0.4816 - s2_acc: 0.4052 - s3_acc: 0.6631 - student_loss_1: 1.4522 - student_loss_2: 1.0622 - student_loss_3: 0.6020 - distillation_loss_t_s1: 0.0170 - distillation_loss_s1_s2: 0.0135 - distillation_loss_s1_s3: 0.0148 - distillation_loss_t_s2: 0.0115 - distillation_loss_s2_s1: 0.0253 - distillation_loss_s2_s3: 0.0123 - distillation_loss_t_s3: 0.0134 - distillation_loss_s3_s1: 0.0259 - distillation_loss_s3_s2: 0.0101\n","Epoch 5/5\n","1250/1250 [==============================] - 361s 289ms/step - s1_acc: 0.5220 - s2_acc: 0.4543 - s3_acc: 0.7008 - student_loss_1: 1.1750 - student_loss_2: 0.8577 - student_loss_3: 0.5042 - distillation_loss_t_s1: 0.0153 - distillation_loss_s1_s2: 0.0126 - distillation_loss_s1_s3: 0.0119 - distillation_loss_t_s2: 0.0135 - distillation_loss_s2_s1: 0.0213 - distillation_loss_s2_s3: 0.0124 - distillation_loss_t_s3: 0.0139 - distillation_loss_s3_s1: 0.0203 - distillation_loss_s3_s2: 0.0107\n","313/313 [==============================] - 13s 37ms/step - s1_acc: 0.5410 - s2_acc: 0.4767 - s3_acc: 0.7172 - student_loss_1: 1.1748 - student_loss_2: 1.3295 - student_loss_3: 0.6751\n","313/313 [==============================] - 11s 37ms/step - s1_acc: 0.5453 - s2_acc: 0.4802 - s3_acc: 0.7201 - student_loss_1: 1.1973 - student_loss_2: 1.3316 - student_loss_3: 0.6709\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h3_s1/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h3_s2/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h3_s3/assets\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","313/313 [==============================] - 13s 38ms/step - s1_acc: 0.6269 - s2_acc: 0.5475 - s3_acc: 0.7808 - student_loss_1: 1.1973 - student_loss_2: 1.3316 - student_loss_3: 0.6709\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OA_FEPPgANXR","executionInfo":{"elapsed":808212,"status":"ok","timestamp":1637684471193,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"},"user_tz":300},"outputId":"5c1ab306-d3f8-4946-872c-05a363690668"},"source":["beta = 0.8\n","print(f\"alpha: 0.1; beta: {beta}; gamma: {1 - 0.1 - beta}\")\n","\n","student1 = get_student1()\n","student2 = get_student2()\n","student3 = get_student3()\n","\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    beta=beta,\n","    gamma=(1 - 0.1 - beta),\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_val, y_val)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)\n","\n","student1.save('/saved_models/h3_s1')\n","student2.save('/saved_models/h3_s2')\n","student3.save('/saved_models/h3_s3')\n","\n","student1_test = tf.keras.models.load_model('/saved_models/h3_s1')\n","student2_test = tf.keras.models.load_model('/saved_models/h3_s2')\n","student3_test = tf.keras.models.load_model('/saved_models/h3_s3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)\n","\n","print()\n","print()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["alpha: 0.1; beta: 0.8; gamma: 0.09999999999999998\n","Epoch 1/5\n","938/938 [==============================] - 272s 280ms/step - s1_acc: 0.1506 - s2_acc: 0.1637 - s3_acc: 0.3377 - student_loss_1: 183.0129 - student_loss_2: 2.9730 - student_loss_3: 1.5900 - distillation_loss_t_s1: 0.0210 - distillation_loss_s1_s2: 0.0579 - distillation_loss_s1_s3: 0.0280 - distillation_loss_t_s2: 0.0427 - distillation_loss_s2_s1: 1.8249 - distillation_loss_s2_s3: 0.0236 - distillation_loss_t_s3: 0.0085 - distillation_loss_s3_s1: 1.8027 - distillation_loss_s3_s2: 0.0487\n","Epoch 2/5\n","938/938 [==============================] - 262s 279ms/step - s1_acc: 0.2320 - s2_acc: 0.2338 - s3_acc: 0.4865 - student_loss_1: 2.4310 - student_loss_2: 1.9011 - student_loss_3: 1.1017 - distillation_loss_t_s1: 0.0212 - distillation_loss_s1_s2: 0.0173 - distillation_loss_s1_s3: 0.0219 - distillation_loss_t_s2: 0.0043 - distillation_loss_s2_s1: 0.0439 - distillation_loss_s2_s3: 0.0138 - distillation_loss_t_s3: 0.0105 - distillation_loss_s3_s1: 0.0455 - distillation_loss_s3_s2: 0.0094\n","Epoch 3/5\n","938/938 [==============================] - 263s 280ms/step - s1_acc: 0.2987 - s2_acc: 0.2771 - s3_acc: 0.5601 - student_loss_1: 1.8995 - student_loss_2: 1.7476 - student_loss_3: 0.8757 - distillation_loss_t_s1: 0.0189 - distillation_loss_s1_s2: 0.0156 - distillation_loss_s1_s3: 0.0188 - distillation_loss_t_s2: 0.0061 - distillation_loss_s2_s1: 0.0309 - distillation_loss_s2_s3: 0.0139 - distillation_loss_t_s3: 0.0118 - distillation_loss_s3_s1: 0.0323 - distillation_loss_s3_s2: 0.0105\n","Epoch 4/5\n","938/938 [==============================] - 264s 281ms/step - s1_acc: 0.3474 - s2_acc: 0.3131 - s3_acc: 0.6124 - student_loss_1: 2.8665 - student_loss_2: 1.5773 - student_loss_3: 0.7169 - distillation_loss_t_s1: 0.0183 - distillation_loss_s1_s2: 0.0150 - distillation_loss_s1_s3: 0.0171 - distillation_loss_t_s2: 0.0081 - distillation_loss_s2_s1: 0.1022 - distillation_loss_s2_s3: 0.0133 - distillation_loss_t_s3: 0.0128 - distillation_loss_s3_s1: 0.1027 - distillation_loss_s3_s2: 0.0114\n","Epoch 5/5\n","938/938 [==============================] - 263s 280ms/step - s1_acc: 0.3830 - s2_acc: 0.3483 - s3_acc: 0.6525 - student_loss_1: 1.6043 - student_loss_2: 1.4243 - student_loss_3: 0.5991 - distillation_loss_t_s1: 0.0170 - distillation_loss_s1_s2: 0.0137 - distillation_loss_s1_s3: 0.0147 - distillation_loss_t_s2: 0.0095 - distillation_loss_s2_s1: 0.0345 - distillation_loss_s2_s3: 0.0131 - distillation_loss_t_s3: 0.0133 - distillation_loss_s3_s1: 0.0353 - distillation_loss_s3_s2: 0.0118\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.3985 - s2_acc: 0.3678 - s3_acc: 0.6699 - student_loss_1: 5.0892 - student_loss_2: 1.5393 - student_loss_3: 0.8736\n","313/313 [==============================] - 11s 35ms/step - s1_acc: 0.3953 - s2_acc: 0.3739 - s3_acc: 0.6721 - student_loss_1: 5.1957 - student_loss_2: 1.5503 - student_loss_3: 0.8943\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"LdtRwv_f2Mhn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637795072022,"user_tz":300,"elapsed":1433212,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"2bd2080e-4119-42db-c83c-bc1046057b03"},"source":["beta = 0.85\n","\n","print(f\"alpha: 0.1; beta: {beta}; gamma: {1 - 0.1 - beta}\")\n","\n","student1 = get_student1()\n","student2 = get_student2()\n","student3 = get_student3()\n","\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    beta=beta,\n","    gamma=(1 - 0.1 - beta),\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_val, y_val)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)\n","\n","student1.save('/saved_models/h4_s1')\n","student2.save('/saved_models/h4_s2')\n","student3.save('/saved_models/h4_s3')\n","\n","student1_test = tf.keras.models.load_model('/saved_models/h4_s1')\n","student2_test = tf.keras.models.load_model('/saved_models/h4_s2')\n","student3_test = tf.keras.models.load_model('/saved_models/h4_s3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)\n","\n","print()\n","print()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["alpha: 0.1; beta: 0.85; gamma: 0.050000000000000044\n","Epoch 1/5\n","938/938 [==============================] - 274s 281ms/step - s1_acc: 0.2285 - s2_acc: 0.1443 - s3_acc: 0.3451 - student_loss_1: 196.6288 - student_loss_2: 2.6928 - student_loss_3: 1.5411 - distillation_loss_t_s1: 0.0207 - distillation_loss_s1_s2: 0.0519 - distillation_loss_s1_s3: 0.0261 - distillation_loss_t_s2: 0.0348 - distillation_loss_s2_s1: 1.3101 - distillation_loss_s2_s3: 0.0184 - distillation_loss_t_s3: 0.0083 - distillation_loss_s3_s1: 1.2978 - distillation_loss_s3_s2: 0.0397\n","Epoch 2/5\n","938/938 [==============================] - 264s 281ms/step - s1_acc: 0.3199 - s2_acc: 0.2247 - s3_acc: 0.4985 - student_loss_1: 3.1782 - student_loss_2: 1.6511 - student_loss_3: 1.0840 - distillation_loss_t_s1: 0.0211 - distillation_loss_s1_s2: 0.0171 - distillation_loss_s1_s3: 0.0230 - distillation_loss_t_s2: 0.0065 - distillation_loss_s2_s1: 0.0898 - distillation_loss_s2_s3: 0.0135 - distillation_loss_t_s3: 0.0106 - distillation_loss_s3_s1: 0.0926 - distillation_loss_s3_s2: 0.0086\n","Epoch 3/5\n","938/938 [==============================] - 264s 281ms/step - s1_acc: 0.3722 - s2_acc: 0.3148 - s3_acc: 0.5681 - student_loss_1: 1.9977 - student_loss_2: 1.3255 - student_loss_3: 0.8754 - distillation_loss_t_s1: 0.0198 - distillation_loss_s1_s2: 0.0154 - distillation_loss_s1_s3: 0.0203 - distillation_loss_t_s2: 0.0090 - distillation_loss_s2_s1: 0.0328 - distillation_loss_s2_s3: 0.0122 - distillation_loss_t_s3: 0.0117 - distillation_loss_s3_s1: 0.0352 - distillation_loss_s3_s2: 0.0086\n","Epoch 4/5\n","938/938 [==============================] - 264s 281ms/step - s1_acc: 0.4133 - s2_acc: 0.3773 - s3_acc: 0.6180 - student_loss_1: 1.7603 - student_loss_2: 1.1113 - student_loss_3: 0.7153 - distillation_loss_t_s1: 0.0185 - distillation_loss_s1_s2: 0.0149 - distillation_loss_s1_s3: 0.0178 - distillation_loss_t_s2: 0.0108 - distillation_loss_s2_s1: 0.0254 - distillation_loss_s2_s3: 0.0119 - distillation_loss_t_s3: 0.0125 - distillation_loss_s3_s1: 0.0272 - distillation_loss_s3_s2: 0.0094\n","Epoch 5/5\n","938/938 [==============================] - 263s 281ms/step - s1_acc: 0.4485 - s2_acc: 0.4287 - s3_acc: 0.6570 - student_loss_1: 1.4836 - student_loss_2: 0.9044 - student_loss_3: 0.6024 - distillation_loss_t_s1: 0.0171 - distillation_loss_s1_s2: 0.0147 - distillation_loss_s1_s3: 0.0156 - distillation_loss_t_s2: 0.0129 - distillation_loss_s2_s1: 0.0234 - distillation_loss_s2_s3: 0.0122 - distillation_loss_t_s3: 0.0131 - distillation_loss_s3_s1: 0.0238 - distillation_loss_s3_s2: 0.0103\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.4674 - s2_acc: 0.4528 - s3_acc: 0.6735 - student_loss_1: 1.3123 - student_loss_2: 1.4218 - student_loss_3: 0.8801\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.4737 - s2_acc: 0.4565 - s3_acc: 0.6752 - student_loss_1: 1.3316 - student_loss_2: 1.4501 - student_loss_3: 0.8942\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h4_s1/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h4_s2/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h4_s3/assets\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","313/313 [==============================] - 12s 35ms/step - s1_acc: 0.5741 - s2_acc: 0.5120 - s3_acc: 0.7025 - student_loss_1: 1.3316 - student_loss_2: 1.4501 - student_loss_3: 0.8942\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KfCE_EFSAOFI","executionInfo":{"elapsed":1367235,"status":"ok","timestamp":1637685838419,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"},"user_tz":300},"outputId":"ff3db811-3ac4-49ad-d635-e950ee89ecae"},"source":["beta = 0.85\n","\n","print(f\"alpha: 0.1; beta: {beta}; gamma: {1 - 0.1 - beta}\")\n","\n","student1 = get_student1()\n","student2 = get_student2()\n","student3 = get_student3()\n","\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    beta=beta,\n","    gamma=(1 - 0.1 - beta),\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_val, y_val)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)\n","\n","student1.save('/saved_models/h4_s1')\n","student2.save('/saved_models/h4_s2')\n","student3.save('/saved_models/h4_s3')\n","\n","student1_test = tf.keras.models.load_model('/saved_models/h4_s1')\n","student2_test = tf.keras.models.load_model('/saved_models/h4_s2')\n","student3_test = tf.keras.models.load_model('/saved_models/h4_s3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)\n","\n","print()\n","print()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["alpha: 0.1; beta: 0.85; gamma: 0.050000000000000044\n","Epoch 1/5\n","938/938 [==============================] - 272s 280ms/step - s1_acc: 0.1653 - s2_acc: 0.1158 - s3_acc: 0.3494 - student_loss_1: 148.6810 - student_loss_2: 3.3437 - student_loss_3: 1.5249 - distillation_loss_t_s1: 0.0227 - distillation_loss_s1_s2: 0.0670 - distillation_loss_s1_s3: 0.0287 - distillation_loss_t_s2: 0.0474 - distillation_loss_s2_s1: 0.9875 - distillation_loss_s2_s3: 0.0242 - distillation_loss_t_s3: 0.0084 - distillation_loss_s3_s1: 0.9669 - distillation_loss_s3_s2: 0.0558\n","Epoch 2/5\n","938/938 [==============================] - 263s 280ms/step - s1_acc: 0.2543 - s2_acc: 0.1694 - s3_acc: 0.5028 - student_loss_1: 2.9807 - student_loss_2: 1.8834 - student_loss_3: 1.0756 - distillation_loss_t_s1: 0.0238 - distillation_loss_s1_s2: 0.0195 - distillation_loss_s1_s3: 0.0243 - distillation_loss_t_s2: 0.0050 - distillation_loss_s2_s1: 0.1025 - distillation_loss_s2_s3: 0.0146 - distillation_loss_t_s3: 0.0107 - distillation_loss_s3_s1: 0.1022 - distillation_loss_s3_s2: 0.0099\n","Epoch 3/5\n","938/938 [==============================] - 263s 280ms/step - s1_acc: 0.3096 - s2_acc: 0.2636 - s3_acc: 0.5716 - student_loss_1: 2.0683 - student_loss_2: 1.5487 - student_loss_3: 0.8690 - distillation_loss_t_s1: 0.0221 - distillation_loss_s1_s2: 0.0172 - distillation_loss_s1_s3: 0.0221 - distillation_loss_t_s2: 0.0079 - distillation_loss_s2_s1: 0.0371 - distillation_loss_s2_s3: 0.0134 - distillation_loss_t_s3: 0.0119 - distillation_loss_s3_s1: 0.0396 - distillation_loss_s3_s2: 0.0097\n","Epoch 4/5\n","938/938 [==============================] - 263s 281ms/step - s1_acc: 0.3485 - s2_acc: 0.3282 - s3_acc: 0.6207 - student_loss_1: 2.0541 - student_loss_2: 1.3919 - student_loss_3: 0.7117 - distillation_loss_t_s1: 0.0201 - distillation_loss_s1_s2: 0.0157 - distillation_loss_s1_s3: 0.0184 - distillation_loss_t_s2: 0.0095 - distillation_loss_s2_s1: 0.0465 - distillation_loss_s2_s3: 0.0124 - distillation_loss_t_s3: 0.0127 - distillation_loss_s3_s1: 0.0487 - distillation_loss_s3_s2: 0.0105\n","Epoch 5/5\n","938/938 [==============================] - 264s 281ms/step - s1_acc: 0.3883 - s2_acc: 0.3763 - s3_acc: 0.6589 - student_loss_1: 1.4211 - student_loss_2: 1.2485 - student_loss_3: 0.6019 - distillation_loss_t_s1: 0.0194 - distillation_loss_s1_s2: 0.0156 - distillation_loss_s1_s3: 0.0173 - distillation_loss_t_s2: 0.0111 - distillation_loss_s2_s1: 0.0238 - distillation_loss_s2_s3: 0.0131 - distillation_loss_t_s3: 0.0133 - distillation_loss_s3_s1: 0.0246 - distillation_loss_s3_s2: 0.0114\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.4120 - s2_acc: 0.4005 - s3_acc: 0.6760 - student_loss_1: 1.4578 - student_loss_2: 1.3821 - student_loss_3: 0.8050\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.4205 - s2_acc: 0.4076 - s3_acc: 0.6794 - student_loss_1: 1.4875 - student_loss_2: 1.3990 - student_loss_3: 0.8125\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"GVbN_07y2Owd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637796489140,"user_tz":300,"elapsed":1416381,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"}},"outputId":"79c3dd61-96b1-45dc-bd04-3b0c8af5f54b"},"source":["beta = 0.9\n","\n","print(f\"alpha: 0.1; beta: {beta}; gamma: {1 - 0.1 - beta}\")\n","\n","student1 = get_student1()\n","student2 = get_student2()\n","student3 = get_student3()\n","\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    beta=beta,\n","    gamma=(1 - 0.1 - beta),\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_val, y_val)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)\n","\n","student1.save('/saved_models/h5_s1')\n","student2.save('/saved_models/h5_s2')\n","student3.save('/saved_models/h5_s3')\n","\n","student1_test = tf.keras.models.load_model('/saved_models/h5_s1')\n","student2_test = tf.keras.models.load_model('/saved_models/h5_s2')\n","student3_test = tf.keras.models.load_model('/saved_models/h5_s3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)\n","\n","print()\n","print()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["alpha: 0.1; beta: 0.9; gamma: 0.0\n","Epoch 1/5\n","938/938 [==============================] - 280s 284ms/step - s1_acc: 0.2508 - s2_acc: 0.1105 - s3_acc: 0.3584 - student_loss_1: 179.4278 - student_loss_2: 2.9543 - student_loss_3: 1.5237 - distillation_loss_t_s1: 0.0218 - distillation_loss_s1_s2: 0.0687 - distillation_loss_s1_s3: 0.0371 - distillation_loss_t_s2: 0.0485 - distillation_loss_s2_s1: 1.2498 - distillation_loss_s2_s3: 0.0326 - distillation_loss_t_s3: 0.0083 - distillation_loss_s3_s1: 1.2442 - distillation_loss_s3_s2: 0.0473\n","Epoch 2/5\n","938/938 [==============================] - 266s 284ms/step - s1_acc: 0.3500 - s2_acc: 0.1172 - s3_acc: 0.5033 - student_loss_1: 4.7461 - student_loss_2: 2.2265 - student_loss_3: 1.0814 - distillation_loss_t_s1: 0.0223 - distillation_loss_s1_s2: 0.0218 - distillation_loss_s1_s3: 0.0239 - distillation_loss_t_s2: 0.0011 - distillation_loss_s2_s1: 0.2255 - distillation_loss_s2_s3: 0.0176 - distillation_loss_t_s3: 0.0106 - distillation_loss_s3_s1: 0.2210 - distillation_loss_s3_s2: 0.0126\n","Epoch 3/5\n","938/938 [==============================] - 266s 284ms/step - s1_acc: 0.3963 - s2_acc: 0.1499 - s3_acc: 0.5727 - student_loss_1: 2.6576 - student_loss_2: 1.9372 - student_loss_3: 0.8591 - distillation_loss_t_s1: 0.0195 - distillation_loss_s1_s2: 0.0180 - distillation_loss_s1_s3: 0.0203 - distillation_loss_t_s2: 0.0036 - distillation_loss_s2_s1: 0.0715 - distillation_loss_s2_s3: 0.0160 - distillation_loss_t_s3: 0.0118 - distillation_loss_s3_s1: 0.0708 - distillation_loss_s3_s2: 0.0125\n","Epoch 4/5\n","938/938 [==============================] - 265s 283ms/step - s1_acc: 0.4367 - s2_acc: 0.2083 - s3_acc: 0.6233 - student_loss_1: 2.4541 - student_loss_2: 1.4930 - student_loss_3: 0.6931 - distillation_loss_t_s1: 0.0180 - distillation_loss_s1_s2: 0.0148 - distillation_loss_s1_s3: 0.0174 - distillation_loss_t_s2: 0.0079 - distillation_loss_s2_s1: 0.0872 - distillation_loss_s2_s3: 0.0135 - distillation_loss_t_s3: 0.0127 - distillation_loss_s3_s1: 0.0899 - distillation_loss_s3_s2: 0.0113\n","Epoch 5/5\n","938/938 [==============================] - 265s 283ms/step - s1_acc: 0.4721 - s2_acc: 0.2704 - s3_acc: 0.6625 - student_loss_1: 1.6814 - student_loss_2: 1.2252 - student_loss_3: 0.5849 - distillation_loss_t_s1: 0.0173 - distillation_loss_s1_s2: 0.0137 - distillation_loss_s1_s3: 0.0158 - distillation_loss_t_s2: 0.0099 - distillation_loss_s2_s1: 0.0331 - distillation_loss_s2_s3: 0.0130 - distillation_loss_t_s3: 0.0133 - distillation_loss_s3_s1: 0.0344 - distillation_loss_s3_s2: 0.0110\n","313/313 [==============================] - 12s 34ms/step - s1_acc: 0.4885 - s2_acc: 0.3048 - s3_acc: 0.6802 - student_loss_1: 1.9142 - student_loss_2: 1.3953 - student_loss_3: 0.7920\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.4911 - s2_acc: 0.3176 - s3_acc: 0.6836 - student_loss_1: 1.9012 - student_loss_2: 1.4308 - student_loss_3: 0.7955\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h5_s1/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h5_s2/assets\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Project/models/saved_models/h5_s3/assets\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","313/313 [==============================] - 12s 35ms/step - s1_acc: 0.5315 - s2_acc: 0.5110 - s3_acc: 0.7421 - student_loss_1: 1.9012 - student_loss_2: 1.4308 - student_loss_3: 0.7955\n","\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tG204jubAOzp","executionInfo":{"elapsed":1369189,"status":"ok","timestamp":1637687209153,"user":{"displayName":"SAGAR PALAO","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTDf2UHUjQHZ__MXniMro-lJzV2OZFc6ghDLmGUQ=s64","userId":"13881692418936951811"},"user_tz":300},"outputId":"ae6b3aa2-1868-46a2-9cee-e5a6259cdf6e"},"source":["beta = 0.9\n","\n","print(f\"alpha: 0.1; beta: {beta}; gamma: {1 - 0.1 - beta}\")\n","\n","student1 = get_student1()\n","student2 = get_student2()\n","student3 = get_student3()\n","\n","distiller = Distiller(student1=student1, student2=student2, student3=student3, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    beta=beta,\n","    gamma=(1 - 0.1 - beta),\n","    temperature=10,\n",")\n","\n","# Distill teacher to student\n","distiller.fit(x_train, y_train, epochs=5)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_val, y_val)\n","\n","# Evaluate student on test dataset\n","distiller.evaluate(x_test, y_test)\n","\n","student1.save('/saved_models/h5_s1')\n","student2.save('/saved_models/h5_s2')\n","student3.save('/saved_models/h5_s3')\n","\n","student1_test = tf.keras.models.load_model('/saved_models/h5_s1')\n","student2_test = tf.keras.models.load_model('/saved_models/h5_s2')\n","student3_test = tf.keras.models.load_model('/saved_models/h5_s3')\n","\n","# Initialize and compile distiller\n","distiller_test = Distiller(student1=student1_test, student2=student2_test, student3=student3_test, teacher=teacher)\n","metric_student1 = keras.metrics.SparseCategoricalAccuracy(name='s1_acc')\n","metric_student2 = keras.metrics.SparseCategoricalAccuracy(name='s2_acc')\n","metric_student3 = keras.metrics.SparseCategoricalAccuracy(name='s3_acc')\n","\n","distiller_test.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[metric_student1, metric_student2, metric_student3],\n","    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    distillation_loss_fn=keras.losses.KLDivergence(),\n","    alpha=0.1,\n","    temperature=10,\n",")\n","\n","# Evaluate student on test dataset\n","distiller_test.evaluate(x_test, y_test)\n","\n","print()\n","print()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["alpha: 0.1; beta: 0.9; gamma: 0.0\n","Epoch 1/5\n","938/938 [==============================] - 273s 280ms/step - s1_acc: 0.1524 - s2_acc: 0.2163 - s3_acc: 0.3603 - student_loss_1: 150.6048 - student_loss_2: 2.5937 - student_loss_3: 1.5220 - distillation_loss_t_s1: 0.0213 - distillation_loss_s1_s2: 0.0501 - distillation_loss_s1_s3: 0.0289 - distillation_loss_t_s2: 0.0356 - distillation_loss_s2_s1: 1.1885 - distillation_loss_s2_s3: 0.0238 - distillation_loss_t_s3: 0.0082 - distillation_loss_s3_s1: 1.1677 - distillation_loss_s3_s2: 0.0392\n","Epoch 2/5\n","938/938 [==============================] - 263s 280ms/step - s1_acc: 0.2376 - s2_acc: 0.3227 - s3_acc: 0.5035 - student_loss_1: 3.1627 - student_loss_2: 1.6043 - student_loss_3: 1.0893 - distillation_loss_t_s1: 0.0213 - distillation_loss_s1_s2: 0.0173 - distillation_loss_s1_s3: 0.0237 - distillation_loss_t_s2: 0.0073 - distillation_loss_s2_s1: 0.0885 - distillation_loss_s2_s3: 0.0137 - distillation_loss_t_s3: 0.0105 - distillation_loss_s3_s1: 0.0906 - distillation_loss_s3_s2: 0.0084\n","Epoch 3/5\n","938/938 [==============================] - 263s 280ms/step - s1_acc: 0.2820 - s2_acc: 0.3840 - s3_acc: 0.5711 - student_loss_1: 2.0903 - student_loss_2: 1.4000 - student_loss_3: 0.8699 - distillation_loss_t_s1: 0.0195 - distillation_loss_s1_s2: 0.0156 - distillation_loss_s1_s3: 0.0202 - distillation_loss_t_s2: 0.0093 - distillation_loss_s2_s1: 0.0391 - distillation_loss_s2_s3: 0.0129 - distillation_loss_t_s3: 0.0118 - distillation_loss_s3_s1: 0.0411 - distillation_loss_s3_s2: 0.0094\n","Epoch 4/5\n","938/938 [==============================] - 263s 280ms/step - s1_acc: 0.3290 - s2_acc: 0.4299 - s3_acc: 0.6202 - student_loss_1: 2.4696 - student_loss_2: 1.2297 - student_loss_3: 0.7111 - distillation_loss_t_s1: 0.0180 - distillation_loss_s1_s2: 0.0151 - distillation_loss_s1_s3: 0.0171 - distillation_loss_t_s2: 0.0112 - distillation_loss_s2_s1: 0.0697 - distillation_loss_s2_s3: 0.0126 - distillation_loss_t_s3: 0.0125 - distillation_loss_s3_s1: 0.0709 - distillation_loss_s3_s2: 0.0105\n","Epoch 5/5\n","938/938 [==============================] - 264s 281ms/step - s1_acc: 0.3665 - s2_acc: 0.4708 - s3_acc: 0.6594 - student_loss_1: 1.8740 - student_loss_2: 1.0560 - student_loss_3: 0.5892 - distillation_loss_t_s1: 0.0180 - distillation_loss_s1_s2: 0.0163 - distillation_loss_s1_s3: 0.0166 - distillation_loss_t_s2: 0.0134 - distillation_loss_s2_s1: 0.0460 - distillation_loss_s2_s3: 0.0136 - distillation_loss_t_s3: 0.0132 - distillation_loss_s3_s1: 0.0457 - distillation_loss_s3_s2: 0.0119\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.3860 - s2_acc: 0.4892 - s3_acc: 0.6774 - student_loss_1: 1.5745 - student_loss_2: 1.3627 - student_loss_3: 0.7943\n","313/313 [==============================] - 11s 34ms/step - s1_acc: 0.3924 - s2_acc: 0.4916 - s3_acc: 0.6813 - student_loss_1: 1.5972 - student_loss_2: 1.3917 - student_loss_3: 0.8072\n","\n","\n"]}]}]}